{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "284a6008",
   "metadata": {},
   "source": [
    "# Ranking Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ce1d6",
   "metadata": {},
   "source": [
    "Ranking model is able to assist retrieval by ranking all the items from highest to lowest, predcting a probablity that a user may or may not like it. Ranking model is useful to filter out items that are not relevant for the user before retrieval task, making retrieval task much more accurate and efficient.\n",
    "\n",
    "In this example,. we will look at a very simple ranking model, and after that, we shall see how we can add more features and combine ranking and retrieval model into a multitask model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b2d9c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import necessary libraries\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a8f3e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>product_category</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "      <th>review_score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>product_code</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>housewares</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.99</td>\n",
       "      <td>4</td>\n",
       "      <td>1.506942e+09</td>\n",
       "      <td>87285b34884572647811a353c7ac498a</td>\n",
       "      <td>housewares SKU 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>barreiras</td>\n",
       "      <td>BA</td>\n",
       "      <td>perfumery</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118.70</td>\n",
       "      <td>4</td>\n",
       "      <td>1.532465e+09</td>\n",
       "      <td>595fac2a385ac33a80bd5114aec74eb8</td>\n",
       "      <td>perfumery SKU 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>vianopolis</td>\n",
       "      <td>GO</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.90</td>\n",
       "      <td>5</td>\n",
       "      <td>1.533718e+09</td>\n",
       "      <td>aa4383b373c6aca5d8797843e5594415</td>\n",
       "      <td>auto SKU 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          order_id order_purchase_timestamp  \\\n",
       "0           0  e481f51cbdc54678b7cc49136f2d6af7      2017-10-02 10:56:33   \n",
       "1           1  53cdb2fc8bc7dce0b6741e2150273451      2018-07-24 20:41:37   \n",
       "2           2  47770eb9100c2d0c44946d9cf07ec65d      2018-08-08 08:38:49   \n",
       "\n",
       "                            user_id customer_city customer_state  \\\n",
       "0  9ef432eb6251297304e76186b10a928d     sao paulo             SP   \n",
       "1  b0830fb4747a6c6d20dea0b8c802d7ef     barreiras             BA   \n",
       "2  41ce2a54c0b03bf3443c3d931a367089    vianopolis             GO   \n",
       "\n",
       "  product_category  quantity   price  review_score     timestamp  \\\n",
       "0       housewares       1.0   29.99             4  1.506942e+09   \n",
       "1        perfumery       1.0  118.70             4  1.532465e+09   \n",
       "2             auto       1.0  159.90             5  1.533718e+09   \n",
       "\n",
       "                       product_code        product_id  \n",
       "0  87285b34884572647811a353c7ac498a  housewares SKU 0  \n",
       "1  595fac2a385ac33a80bd5114aec74eb8   perfumery SKU 0  \n",
       "2  aa4383b373c6aca5d8797843e5594415        auto SKU 0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterdf = pd.read_csv('../data_cleaned/brazildata_mod.csv')\n",
    "masterdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd63c56",
   "metadata": {},
   "source": [
    "# Idenfity features that we need, and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87b42247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82597"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(masterdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2493a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### standardize item data types, especially string, float, and integer\n",
    "\n",
    "masterdf[['user_id',      \n",
    "          'product_id',  \n",
    "         ]] = masterdf[['user_id','product_id']].astype(str)\n",
    "\n",
    "# we will play around with the data type of the quantity, \n",
    "# which you shall see later it affects the accuracy of the prediction.\n",
    "\n",
    "masterdf['quantity'] = masterdf['quantity'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07fd7a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define interactions data and user data\n",
    "\n",
    "### interactions \n",
    "### here we create a reference table of the user , item, and quantity purchased\n",
    "interactions_dict = masterdf.groupby(['user_id', 'product_id'])[ 'quantity'].sum().reset_index()\n",
    "\n",
    "## we tansform the table inta a dictionary , which then we feed into tensor slices\n",
    "# this step is crucial as this will be the type of data fed into the embedding layers\n",
    "interactions_dict = {name: np.array(value) for name, value in interactions_dict.items()}\n",
    "interactions = tf.data.Dataset.from_tensor_slices(interactions_dict)\n",
    "\n",
    "## we do similar step for item, where this is the reference table for items to be recommended\n",
    "items_dict = masterdf[['product_id']].drop_duplicates()\n",
    "items_dict = {name: np.array(value) for name, value in items_dict.items()}\n",
    "items = tf.data.Dataset.from_tensor_slices(items_dict)\n",
    "\n",
    "## map the features in interactions and items to an identifier that we will use throught the embedding layers\n",
    "## do it for all the items in interaction and item table\n",
    "## you may often get itemtype error, so that is why here i am casting the quantity type as float to ensure consistency\n",
    "interactions = interactions.map(lambda x: {\n",
    "    'user_id' : x['user_id'], \n",
    "    'product_id' : x['product_id'], \n",
    "    'quantity' : float(x['quantity']),\n",
    "\n",
    "})\n",
    "\n",
    "items = items.map(lambda x: x['product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "821d7a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_item_titles = np.unique(np.concatenate(list(items.batch(1000))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(interactions.batch(1_000).map(lambda x: x[\"user_id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dda9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle data and split between train and test.\n",
    "tf.random.set_seed(42)\n",
    "shuffled = interactions.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(60_000)\n",
    "test = shuffled.skip(60_000).take(20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6163bf6",
   "metadata": {},
   "source": [
    "Here, many embedding layers works similarly with retrieval model, with addition of multiple hidden layers under Sequential latyers, where we can stack multiple dense layers. \n",
    "\n",
    "We split the query and candidate tower separately, and call them later into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5b5e645",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # Compute embeddings for users.\n",
    "        self.user_embeddings = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Compute embeddings for movies.\n",
    "        self.movie_embeddings = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_item_titles, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_item_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Compute predictions.\n",
    "        self.ratings = tf.keras.Sequential([\n",
    "          # Learn multiple dense layers.\n",
    "          tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "          # Make rating predictions in the final layer.\n",
    "          tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        user_id, movie_title = inputs\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_id)\n",
    "        movie_embedding = self.movie_embeddings(movie_title)\n",
    "\n",
    "        return self.ratings(tf.concat([user_embedding, movie_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a0d37",
   "metadata": {},
   "source": [
    "This model takes user ids and movie titles, and outputs a predicted rating, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb165003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['9ef432eb6251297304e76186b10a928d']\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['perfumery SKU 0']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.01101889]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RankingModel()(([\"9ef432eb6251297304e76186b10a928d\"], [\"perfumery SKU 0\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc274d",
   "metadata": {},
   "source": [
    "Here we insert the query and candidate model built above into the model. The only difference from retrieval task is that we use ranking task, and we calculate the accuracy metrics using RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2e577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetailModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ranking_model: tf.keras.Model = RankingModel()\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "          loss = tf.keras.losses.MeanSquaredError(),\n",
    "          metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        rating_predictions = self.ranking_model(\n",
    "            (features[\"user_id\"], features[\"product_id\"]))\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(labels=features[\"quantity\"], predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef21b6",
   "metadata": {},
   "source": [
    "As usual, we call fit on train and test data, and the evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a59824",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RetailModel()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.5))\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "\n",
    "model.fit(cached_train, epochs=100)\n",
    "\n",
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79b1c469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 14ms/step - root_mean_squared_error: 2.0219 - loss: 4.1635 - regularization_loss: 0.0000e+00 - total_loss: 4.1635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 2.0219151973724365,\n",
       " 'loss': 4.294068336486816,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 4.294068336486816}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe64b5e7",
   "metadata": {},
   "source": [
    "The RMSE is not very good, which we shall see later how we can improve it by adding more features and combining ranking and retrieval model together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6c2d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow 2.0)",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
